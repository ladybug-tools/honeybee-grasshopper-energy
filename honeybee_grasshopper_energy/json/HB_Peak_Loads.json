{
  "version": "1.8.0", 
  "nickname": "PeakLoads", 
  "outputs": [
    [
      {
        "access": "None", 
        "name": "peak_cool", 
        "description": "A list of numbers that align with the input _rooms and correspond\nto the peak cooling of each room on the summer design day in Watts.\nNote that, for multi-room simulations, the individual room peaks may\nnot be coincident, meaning that summing these values together won't\ngive a correct sense of the size of cetral cooling equipment serving\nmultiple rooms. For such equipment, the max of the cooling data\ncollection should be used.", 
        "type": null, 
        "default": null
      }, 
      {
        "access": "None", 
        "name": "peak_heat", 
        "description": "A list of numbers that align with the input _rooms and correspond\nto the peak heating of each room on the winter design day in Watts.\nNote that, for multi-room simulations, the individual room peaks may\nnot be coincident, meaning that summing these values together won't\ngive a correct sense of the size of cetral heating equipment serving\nmultiple rooms. For such equipment, the max of the heating data\ncollection should be used.", 
        "type": null, 
        "default": null
      }, 
      {
        "access": "None", 
        "name": "cooling", 
        "description": "A Data Collection indicating the combined cooling demand of the rooms\nat each simulation timestep of the summer design day. This can be\nplugged into the \"LB Monthly Chart\" component to visualize the demand\nor it can be deconstructed with the \"LB Deconstruct Data\" component\nfor analysis.", 
        "type": null, 
        "default": null
      }, 
      {
        "access": "None", 
        "name": "heating", 
        "description": "A Data Collection indicating the combined heating demand of the rooms\nat each simulation timestepof the winter design day. This can be\nplugged into the \"LB Monthly Chart\" component to visualize the demand\nor it can be deconstructed with the \"LB Deconstruct Data\" component\nfor analysis.", 
        "type": null, 
        "default": null
      }, 
      {
        "access": "None", 
        "name": "cool_bal", 
        "description": "A list of data collections for the various terms of the sensible load\nbalance that contribute to peak cooling on the summer design day. These\ncan be plugged into the \"LB Monthly Chart\" component (with stack_ set\nto True) to visualize the terms contributing to the peak. Will be\nNone unless run_bal_ is set to True.", 
        "type": null, 
        "default": null
      }, 
      {
        "access": "None", 
        "name": "heat_bal", 
        "description": "A list of data collections for the various terms of the sensible load\nbalance that contribute to peak heating on the summer design day. These\ncan be plugged into the \"LB Monthly Chart\" component (with stack_ set\nto True) to visualize the terms contributing to the peak. Will be\nNone unless run_bal_ is set to True.", 
        "type": null, 
        "default": null
      }
    ]
  ], 
  "inputs": [
    {
      "access": "list", 
      "name": "_rooms", 
      "description": "A list of Honeybee Rooms for which peak loads will be computed.", 
      "type": "System.Object", 
      "default": null
    }, 
    {
      "access": "list", 
      "name": "shades_", 
      "description": "An optional list of Honeybee Shades that can block the sun to\nthe input _rooms.", 
      "type": "System.Object", 
      "default": null
    }, 
    {
      "access": "item", 
      "name": "_ddy_file", 
      "description": "Path to a .ddy file on your system as a text string, which contains\ndesign day conditions for the peak load analysis. This can also\nbe the path to an .epw file, in which case design days will be\ndetermined by statitically analysing the annual data to approximate\n0.4% and 99.6% design conditions.\n_\nNote that custom .ddy files can be crafted from EPW or STAT data\nusing the \"LB EPW to DDY\" component. They can also also be created\nfrom raw sets of outdoor conditions using the \"DF Construct Design\nDay\" and \"DF Write DDY\" components.\n_\nWhen constructing custom DDY files, it is recommended that the .ddy\nfile contain only one summer and one winter design day. Alternatively,\nif you wish to specify multiple cooling design day conditions for\neach month of the year (to evaluate solar load in each month),\neach of these cooling design days should contain \"0.4%\" in the\ndesign day name along with \" DB=>MWB\". This convention will\nautomatically be followed when using the \"monthly_cool_\" option\non the \"LB EPW to DDY\" component.\n_\nIn this situation of multiple monthly cooling design days, this\ncomponent will report peak_cool zone sizes that correspond to the\nhighest month for each zone and the output cooling data collection\nwill be for the month with the highest coincident peak cooling.", 
      "type": "string", 
      "default": null
    }, 
    {
      "access": "item", 
      "name": "_north_", 
      "description": "A number between -360 and 360 for the counterclockwise difference\nbetween the North and the positive Y-axis in degrees.\n90 is West and 270 is East. (Default: 0).", 
      "type": "System.Object", 
      "default": null
    }, 
    {
      "access": "item", 
      "name": "_timestep_", 
      "description": "An integer for the number of timesteps per hour at which the energy\nsimulation will be run and results reported. It is recommended that\nthis be at least 6 but it can be increased to better capture\nthe minute in which peak cooling occurs. (Default: 6).\nThe following values are acceptable:\n(1, 2, 3, 4, 5, 6, 10, 12, 15, 20, 30, 60)", 
      "type": "int", 
      "default": null
    }, 
    {
      "access": "item", 
      "name": "run_bal_", 
      "description": "Set to True to have the load balance computed after the\nsimulation is run. This ensures that data collections for various\nterms of the load balance are output from the \"balance\".\nThis can help explain why the loads are what they are but can\nalso increase the component run time. (Default: False).", 
      "type": "bool", 
      "default": null
    }, 
    {
      "access": "item", 
      "name": "_run", 
      "description": "Set to \"True\" to run the simulation to obtain annual loads. This can\nalso be the integer 2 to run the simulation while being able to see\nthe simulation process (with a batch window).", 
      "type": "int", 
      "default": null
    }
  ], 
  "subcategory": "5 :: Simulate", 
  "code": "\nimport os\nimport subprocess\nimport json\n\ntry:\n    from ladybug.futil import write_to_file_by_name, nukedir\n    from ladybug.ddy import DDY\n    from ladybug.epw import EPW\n    from ladybug.sql import SQLiteResult\n    from ladybug.datacollection import HourlyContinuousCollection\n    from ladybug.header import Header\n    from ladybug.analysisperiod import AnalysisPeriod\n    from ladybug.datatype.power import Power\nexcept ImportError as e:\n    raise ImportError('\\nFailed to import ladybug:\\n\\t{}'.format(e))\n\ntry:\n    from honeybee.config import folders\n    from honeybee.model import Model\nexcept ImportError as e:\n    raise ImportError('\\nFailed to import honeybee:\\n\\t{}'.format(e))\n\ntry:\n    from honeybee_energy.result.loadbalance import LoadBalance\n    from honeybee_energy.simulation.parameter import SimulationParameter\n    from honeybee_energy.run import run_idf\n    from honeybee_energy.result.err import Err\n    from honeybee_energy.result.zsz import ZSZ\n    from honeybee_energy.writer import energyplus_idf_version\n    from honeybee_energy.config import folders as energy_folders\nexcept ImportError as e:\n    raise ImportError('\\nFailed to import honeybee_energy:\\n\\t{}'.format(e))\n\ntry:\n    from lbt_recipes.version import check_energyplus_version\nexcept ImportError as e:\n    raise ImportError('\\nFailed to import lbt_recipes:\\n\\t{}'.format(e))\n\ntry:\n    from ladybug_{{cad}}.togeometry import to_vector2d\n    from ladybug_{{cad}}.config import tolerance, angle_tolerance, units_system\n    from ladybug_{{cad}}.{{plugin}} import all_required_inputs, give_warning\nexcept ImportError as e:\n    raise ImportError('\\nFailed to import ladybug_{{cad}}:\\n\\t{}'.format(e))\n\n\ndef check_for_filter_failure(des_days):\n    \"\"\"Raise a ValueError in the event that the design-dsy filtering process failed.\"\"\"\n    if len(des_days) == 0:\n        raise ValueError(\n            'Failed to filter the design days in the .ddy file to find the most '\n            'appropriate one for sensible peak loads.\\nTry connecting an .epw file '\n            'instead.\\n Or try creating your own .ddy file with a single summer '\n            'and winter design day.'\n        )\n\n\ndef find_max_cooling_des_day(des_days, sim_par, base_strs):\n    \"\"\"Find the cooling design day with the highest coincident peak load.\"\"\"\n    # create sizing parameters with all of the design days\n    sim_par_dup = sim_par.duplicate()\n    sim_par_dup.output.outputs = None\n    for dy in des_days:\n        sim_par_dup.sizing_parameter.add_design_day(dy)\n    # write the IDF and run the sizing calculation\n    idf_str_init = '\\n\\n'.join([sim_par_dup.to_idf()] + base_strs)\n    idf = os.path.join(directory, 'in.idf')\n    write_to_file_by_name(directory, 'in.idf', idf_str_init, True)\n    sql, zsz, rdd, html, err = run_idf(idf, silent=True)\n    # determine the design day with the highest peak using the sizing results\n    sql_obj = SQLiteResult(sql)\n    d_day_dict = {d_day.name.upper(): [0, d_day] for d_day in des_days}\n    peak_cool_dict = {}\n    for zs in sql_obj.zone_cooling_sizes:\n        d_day_dict[zs.design_day_name][0] += zs.calculated_design_load\n        peak_cool_dict[zs.zone_name] = zs.calculated_design_load\n    day_loads = list(d_day_dict.values())\n    day_loads.sort(key=lambda y: y[0])\n    \n    return [day_loads[-1][1]], peak_cool_dict\n\n\ndef check_and_filter_des_days(sim_par, des_days, day_type, base_strs=None):\n    \"\"\"Filter design days to get the most appropriate one and assing it to sim_par.\"\"\"\n    if len(des_days) == 0:\n        raise ValueError('No {}s were found in the connected .ddy file.'.format(day_type))\n    elif len(des_days) == 1:  # just assign the one design day\n        _sim_par_.sizing_parameter.add_design_day(des_days[0])\n    else:  # find the most appropriate design day by percent\n        if day_type == 'WinterDesignDay':\n            des_days = [dday for dday in des_days if '99.6%' in dday.name]\n        else:\n            des_days = [dday for dday in des_days if '.4%' in dday.name or '.2%' in dday.name]\n        check_for_filter_failure(des_days)\n        if len(des_days) == 1:\n            _sim_par_.sizing_parameter.add_design_day(des_days[0])\n        else:  # find the most appropriate design day bu type\n            peak_cool_dict = None\n            if day_type == 'WinterDesignDay':\n                des_days = [dday for dday in des_days if ' DB' in dday.name]\n            else:\n                des_days = [dday for dday in des_days if ' DB=>MCWB' in dday.name or\n                            ' DB=>MWB' in dday.name]\n                if len(des_days) > 1:\n                    des_days, peak_cool_dict = find_max_cooling_des_day(\n                        des_days, sim_par, base_strs)\n            check_for_filter_failure(des_days)\n            if len(des_days) == 1:\n                _sim_par_.sizing_parameter.add_design_day(des_days[0])\n                return peak_cool_dict\n            else:\n                check_for_filter_failure([])\n\n\ndef data_to_load(data_colls, data_type, analysis_period):\n    \"\"\"Convert data collections output by EnergyPlus to a single load collection.\n\n    Args:\n        data_colls: A list of monthly data collections for an energy term.\n        data_type: Text for the data type of the collections (eg. \"Cooling\").\n        analysis_period: AnalysisPeriod object describing the date and timestep\n            of the design day.\n    \"\"\"\n    if len(data_colls) != 0:\n        total_vals = [sum(ts_vals) for ts_vals in zip(*data_colls)]\n    else:  # just make a \"filler\" collection of 0 values\n        total_vals = [0] * (24 * analysis_period.timestep)\n    meta_dat = {'type': data_type}\n    total_head = Header(Power(), 'W', analysis_period, meta_dat)\n    return HourlyContinuousCollection(total_head, total_vals)\n\n\ndef serialize_data(data_dicts):\n    \"\"\"Reserialize a list of collection dictionaries.\"\"\"\n    return [HourlyContinuousCollection.from_dict(dat) for dat in data_dicts]\n\n\ndef filter_data_by_date(filt_date, data):\n    \"\"\"Filter a matrix of data collections by the date in their analysis period.\"\"\"\n    filtered_data = []\n    for data_list in data:\n        flit_list = []\n        for d in data_list:\n            a_per = d.header.analysis_period\n            if a_per.st_month == filt_date.month and a_per.st_day == filt_date.day:\n                flit_list.append(d.to_time_rate_of_change())\n        filtered_data.append(flit_list)\n    return filtered_data\n\n\ndef all_data_load_balance(rooms, data):\n    \"\"\"Get a LoadBalance object from a list of all relavant data collections.\"\"\"\n    return LoadBalance(\n        rooms, lighting_data=data[0], electric_equip_data=data[1],\n        gas_equip_data=data[2], process_data=data[3], service_hot_water_data=data[4],\n        people_data=data[5], solar_data=data[6], infiltration_data=data[7],\n        surface_flow_data=data[8], use_all_solar=True\n    )\n\n\ndef reorder_balance(balance, order):\n    \"\"\"Reorder the terms of a load balance according to the desired names.\"\"\"\n    new_balance = []\n    for term_name in order:\n        for term in balance:\n            if term.header.metadata['type'] == term_name:\n                new_balance.append(term)\n                break\n    return new_balance\n\n\n# List of the output strings that will be requested\nopaque_energy_flow_output = 'Surface Inside Face Conduction Heat Transfer Energy'\nwindow_loss_output = 'Surface Window Heat Loss Energy'\nwindow_gain_output = 'Surface Window Heat Gain Energy'\nall_output = \\\n    [LoadBalance.LI{{PLGN}}TING, LoadBalance.ELECTRIC_EQUIP, LoadBalance.GAS_EQUIP,\n     LoadBalance.PROCESS, LoadBalance.HOT_WATER,\n     LoadBalance.PEOPLE_GAIN, LoadBalance.SOLAR_GAIN,\n     LoadBalance.INFIL_GAIN, LoadBalance.INFIL_LOSS, opaque_energy_flow_output,\n     window_loss_output, window_gain_output]\nterm_order = \\\n    ['Solar', 'Window Conduction', 'Opaque Conduction', 'Infiltration', 'People', 'Lighting',\n     'Electric Equipment', 'Gas Equipment', 'Process Equipment', 'Service Hot Water']\n\n\nif all_required_inputs(ghenv.Component) and _run:\n    # check the presence of energyplus and check that the version is compatible\n    check_energyplus_version()\n\n    # create the Model from the _rooms and shades_\n    _model = Model('Peak_Loads', _rooms, orphaned_shades=shades_, units=units_system(),\n                   tolerance=tolerance, angle_tolerance=angle_tolerance)\n\n    # process the simulation folder name and the directory\n    directory = os.path.join(folders.default_simulation_folder, _model.identifier)\n    sch_directory = os.path.join(directory, 'schedules')\n    nukedir(directory)  # delete any existing files in the directory\n\n    # create simulation parameters for a design-day-optimized E+ sim\n    _sim_par_ = SimulationParameter()\n    _sim_par_.timestep = _timestep_ if _timestep_ is not None else 6\n    _sim_par_.output.reporting_frequency = 'Timestep'\n    _sim_par_.simulation_control.run_for_sizing_periods = True\n    _sim_par_.simulation_control.run_for_run_periods = False\n    if run_bal_:\n        _sim_par_.output.add_zone_energy_use('Sensible')\n        _sim_par_.output.add_gains_and_losses('Sensible')\n        _sim_par_.output.add_surface_energy_flow()\n    # set the north if it is not defaulted\n    if _north_ is not None:\n        try:\n            _sim_par_.north_vector = to_vector2d(_north_)\n        except AttributeError:  # north angle instead of vector\n            _sim_par_.north_angle = float(_north_)\n\n    # create the strings for simulation paramters and model\n    ver_str = energyplus_idf_version() if energy_folders.energyplus_version \\\n        is not None else energyplus_idf_version(compatibe_ep_version)\n    model_str = _model.to.idf(\n        _model, schedule_directory=sch_directory, patch_missing_adjacencies=True)\n\n    # load design days to the simulation parameters\n    peak_cool_dict = None\n    if _ddy_file.lower().endswith('.epw'):  # load design days from EPW\n        epw_obj = EPW(_ddy_file)\n        location = epw_obj.location\n        des_days = epw_obj.best_available_design_days()\n        _sim_par_.sizing_parameter.design_days = reversed(des_days)\n    else:  # load design days from DDY\n        ddy_obj = DDY.from_ddy_file(_ddy_file)\n        location = ddy_obj.location\n        s_days = [day for day in ddy_obj.design_days if day.day_type == 'SummerDesignDay']\n        base_strs = [ver_str, location.to_idf(), model_str]\n        peak_cool_dict = check_and_filter_des_days(\n            _sim_par_, s_days, 'SummerDesignDay', base_strs)\n        w_days = [day for day in ddy_obj.design_days if day.day_type == 'WinterDesignDay']\n        check_and_filter_des_days(_sim_par_, w_days, 'WinterDesignDay')\n\n    # get the dates of the heating and cooling design days\n    h_dt = _sim_par_.sizing_parameter.design_days[1].sky_condition.date\n    c_dt = _sim_par_.sizing_parameter.design_days[0].sky_condition.date\n    tst = _sim_par_.timestep\n    heat_ap = AnalysisPeriod(h_dt.month, h_dt.day, 0, h_dt.month, h_dt.day, 23, tst)\n    cool_ap = AnalysisPeriod(c_dt.month, c_dt.day, 0, c_dt.month, c_dt.day, 23, tst)\n\n    # bring all of the IDF strings together\n    idf_str = '\\n\\n'.join([ver_str, location.to_idf(), _sim_par_.to_idf(), model_str])\n\n    # write the final string into an IDF\n    idf = os.path.join(directory, 'in.idf')\n    write_to_file_by_name(directory, 'in.idf', idf_str, True)\n\n    # run the IDF through EnergyPlus\n    silent = True if _run == 1 else False\n    sql, zsz, rdd, html, err = run_idf(idf, silent=silent)\n    if html is None and err is not None:  # something went wrong; parse the errors\n        err_obj = Err(err)\n        print(err_obj.file_contents)\n        for error in err_obj.fatal_errors:\n            raise Exception(error)\n\n    # parse the result ZSZ and get the timestep data collections\n    if zsz is not None:\n        zsz_obj = ZSZ(zsz)\n        cool_init = zsz_obj.cooling_load_data\n        heat_init = zsz_obj.heating_load_data\n        cooling = data_to_load(cool_init, 'Cooling', cool_ap)\n        heating = data_to_load(heat_init, 'Heating', heat_ap)\n    else:\n        msg = 'None of the rooms in the model are conditioned.\\nAll rooms will ' \\\n            'have a peak load of zero and no cooling data collection will be output.'\n        print(msg)\n        give_warning(ghenv.Component, msg)\n\n    # parse the result sql and get the timestep data collections\n    if os.name == 'nt':  # we are on windows; use IronPython like usual\n        sql_obj = SQLiteResult(sql)\n        if peak_cool_dict is None:\n            peak_cool_dict = {zs.zone_name: zs.calculated_design_load\n                              for zs in sql_obj.zone_cooling_sizes}\n        peak_heat_dict = {zs.zone_name: zs.calculated_design_load\n                          for zs in sql_obj.zone_heating_sizes}\n    else:  # we are on Mac; sqlite3 module doesn't work in Mac IronPython\n        # Execute the honybee CLI to obtain the results via CPython\n        cmds = [folders.python_exe_path, '-m', 'honeybee_energy', 'result',\n                'zone-sizes', sql]\n        custom_env = os.environ.copy()\n        custom_env['PYTHONHOME'] = ''\n        process = subprocess.Popen(cmds, stdout=subprocess.PIPE, env=custom_env)\n        stdout = process.communicate()\n        peak_dicts = json.loads(stdout[0])\n        if peak_cool_dict is None:\n            peak_cool_dict = {zs['zone_name']: zs['calculated_design_load']\n                              for zs in peak_dicts['cooling']}\n        peak_heat_dict = {zs['zone_name']: zs['calculated_design_load']\n                          for zs in peak_dicts['heating']}\n    peak_cool, peak_heat = [], []\n    for rm in _rooms:\n        rm_id = rm.identifier.upper()\n        try:\n            peak_cool.append(peak_cool_dict[rm_id])\n        except KeyError:\n            peak_cool.append(0)\n        try:\n            peak_heat.append(peak_heat_dict[rm_id])\n        except KeyError:\n            peak_heat.append(0)\n\n    # construct the load balance if requested\n    if run_bal_:\n        if os.name == 'nt':  # we are on windows; use IronPython like usual\n            light = sql_obj.data_collections_by_output_name(LoadBalance.LI{{PLGN}}TING)\n            ele_equip = sql_obj.data_collections_by_output_name(LoadBalance.ELECTRIC_EQUIP)\n            gas_equip = sql_obj.data_collections_by_output_name(LoadBalance.GAS_EQUIP)\n            process = sql_obj.data_collections_by_output_name(LoadBalance.PROCESS)\n            hot_water = sql_obj.data_collections_by_output_name(LoadBalance.HOT_WATER)\n            people = sql_obj.data_collections_by_output_name(LoadBalance.PEOPLE_GAIN)\n            solar = sql_obj.data_collections_by_output_name(LoadBalance.SOLAR_GAIN)\n            infil_gain = sql_obj.data_collections_by_output_name(LoadBalance.INFIL_GAIN)\n            infil_loss = sql_obj.data_collections_by_output_name(LoadBalance.INFIL_LOSS)\n            opaque_flow = sql_obj.data_collections_by_output_name(opaque_energy_flow_output)\n            window_loss = sql_obj.data_collections_by_output_name(window_loss_output)\n            window_gain = sql_obj.data_collections_by_output_name(window_gain_output)\n        else:  # we are on Mac; sqlite3 module doesn't work in Mac IronPython\n            # Execute the honybee CLI to obtain the results via CPython\n            cmds = [folders.python_exe_path, '-m', 'honeybee_energy', 'result',\n                    'data-by-outputs', sql]\n            for outp in all_output:\n                out_str = json.dumps(outp) if isinstance(outp, tuple) else '[\"{}\"]'.format(outp)\n                cmds.append(out_str)\n            process = subprocess.Popen(cmds, stdout=subprocess.PIPE, env=custom_env)\n            stdout = process.communicate()\n            data_coll_dicts = json.loads(stdout[0])\n            light = serialize_data(data_coll_dicts[0])\n            ele_equip = serialize_data(data_coll_dicts[1])\n            gas_equip = serialize_data(data_coll_dicts[2])\n            process = serialize_data(data_coll_dicts[3])\n            hot_water = serialize_data(data_coll_dicts[4])\n            people = serialize_data(data_coll_dicts[5])\n            solar = serialize_data(data_coll_dicts[6])\n            infil_gain = serialize_data(data_coll_dicts[7])\n            infil_loss = serialize_data(data_coll_dicts[8])\n            opaque_flow = serialize_data(data_coll_dicts[9])\n            window_loss = serialize_data(data_coll_dicts[10])\n            window_gain = serialize_data(data_coll_dicts[11])\n            for dat in opaque_flow + window_loss + window_gain:\n                dat.header.metadata['Surface'] = dat.header.metadata['Zone']\n\n        infil = LoadBalance.subtract_loss_from_gain(infil_gain, infil_loss)\n        window_flow = []\n        window_flow = LoadBalance.subtract_loss_from_gain(window_gain, window_loss)\n        face_flow = opaque_flow + window_flow\n        all_data = [light, ele_equip, gas_equip, process, hot_water, people, solar, infil, face_flow]\n\n        # construct the cooling design day balance\n        c_data = filter_data_by_date(c_dt, all_data)\n        load_bal = all_data_load_balance(_rooms, c_data)\n        cool_bal = reorder_balance(load_bal.load_balance_terms(), term_order)\n\n        # construct the heating design day balance\n        h_data = filter_data_by_date(h_dt, all_data)\n        load_bal = all_data_load_balance(_rooms, h_data)\n        heat_bal = reorder_balance(load_bal.load_balance_terms(), term_order)\n", 
  "category": "HB-Energy", 
  "name": "HB Peak Loads", 
  "description": "Run Honeybee Rooms through a quick energy simulation to obtain an estimate of\nroom-level peak cooling and heating on summer and winter design days.\n-"
}